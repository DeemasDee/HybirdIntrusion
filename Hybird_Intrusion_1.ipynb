{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Library"
      ],
      "metadata": {
        "id": "o35hmvmzaHde"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99emKIUiZsL2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data + Machine Learning"
      ],
      "metadata": {
        "id": "879vCj5CaWKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load dataset\n",
        "data = pd.read_csv('rout_4_2023_dataset.csv')\n",
        "\n",
        "# 2. Preprocessing data\n",
        "X = data.drop('attack_type', axis=1)\n",
        "y = data['attack_type']\n",
        "\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Encoding labels\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "# 3. Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, stratify=y_encoded)\n",
        "\n",
        "# 4. Train Random Forest model\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Predictions and evaluation\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Random Forest F1-Score:\", f1_score(y_test, y_pred_rf, average='macro'))"
      ],
      "metadata": {
        "id": "2IcrIk7aaKkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deep Learning**\n",
        "\n",
        "tidak perlu dijalankan pada script ini, jika akan menjalankan Script DeepLearning versi lengkap pada cell paling bawah/terbaru"
      ],
      "metadata": {
        "id": "x7jM8bVNaqob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# 1. Define Transformer model architecture\n",
        "def build_transformer_model(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Multi-head attention\n",
        "    attention = layers.MultiHeadAttention(num_heads=2, key_dim=2)(inputs, inputs)\n",
        "    attention = layers.Dropout(0.1)(attention)\n",
        "    attention = layers.LayerNormalization(epsilon=1e-6)(attention + inputs)\n",
        "\n",
        "    # Feed-forward network\n",
        "    ff = layers.Dense(64, activation='relu')(attention)\n",
        "    ff = layers.Dropout(0.1)(ff)\n",
        "    ff = layers.LayerNormalization(epsilon=1e-6)(ff + attention)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(ff)\n",
        "\n",
        "    # Compile model\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# 2. Load and reshape data for Transformer model\n",
        "input_shape = (X_train.shape[1], 1)\n",
        "X_train_reshaped = X_train.reshape((-1, X_train.shape[1], 1))\n",
        "X_test_reshaped = X_test.reshape((-1, X_test.shape[1], 1))\n",
        "\n",
        "# 3. Build and train Transformer model\n",
        "transformer_model = build_transformer_model(input_shape, num_classes=len(set(y_encoded)))\n",
        "transformer_model.fit(X_train_reshaped, y_train, epochs=5, batch_size=32)\n",
        "\n",
        "# 4. Evaluate Transformer model\n",
        "test_loss, test_acc = transformer_model.evaluate(X_test_reshaped, y_test)\n",
        "print(\"Transformer Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "id": "POI5PszTaf6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DeepLearning (FNN, CNN, LTSM, Transformer)**"
      ],
      "metadata": {
        "id": "M-F06im7-5rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Load dataset\n",
        "data = pd.read_csv('rout_4_2023_dataset.csv')  # Ganti dengan path dataset\n",
        "\n",
        "# Preprocessing data\n",
        "X = data.drop('attack_type', axis=1)\n",
        "y = data['attack_type']\n",
        "\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Encoding labels\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, stratify=y_encoded)\n",
        "\n",
        "# Reshape data for CNN, LSTM, and Transformer\n",
        "input_shape = (X_train.shape[1], 1)\n",
        "X_train_reshaped = X_train.reshape((-1, X_train.shape[1], 1))\n",
        "X_test_reshaped = X_test.reshape((-1, X_test.shape[1], 1))\n",
        "num_classes = len(set(y_encoded))\n",
        "\n",
        "# 2. Define FFNN model\n",
        "def build_ffnn_model(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Flatten(input_shape=input_shape),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 3. Define CNN model\n",
        "def build_cnn_model(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 4. Define LSTM model\n",
        "def build_lstm_model(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.LSTM(64, input_shape=input_shape, return_sequences=True),\n",
        "        layers.LSTM(32),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 5. Define Transformer model\n",
        "def build_transformer_model(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Multi-head attention\n",
        "    attention = layers.MultiHeadAttention(num_heads=2, key_dim=2)(inputs, inputs)\n",
        "    attention = layers.Dropout(0.1)(attention)\n",
        "    attention = layers.LayerNormalization(epsilon=1e-6)(attention + inputs)\n",
        "\n",
        "    # Feed-forward network\n",
        "    ff = layers.Dense(64, activation='relu')(attention)\n",
        "    ff = layers.Dropout(0.1)(ff)\n",
        "    ff = layers.LayerNormalization(epsilon=1e-6)(ff + attention)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(ff)\n",
        "\n",
        "    # Compile model\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# 6. Train and evaluate models\n",
        "models_dict = {\n",
        "    \"FFNN\": build_ffnn_model((X_train.shape[1],), num_classes),\n",
        "    \"CNN\": build_cnn_model(input_shape, num_classes),\n",
        "    \"LSTM\": build_lstm_model(input_shape, num_classes),\n",
        "    \"Transformer\": build_transformer_model(input_shape, num_classes)\n",
        "}\n",
        "\n",
        "history_dict = {}\n",
        "for model_name, model in models_dict.items():\n",
        "    print(f\"Training {model_name} model...\")\n",
        "    if model_name in ['CNN', 'LSTM', 'Transformer']:\n",
        "        history = model.fit(X_train_reshaped, y_train, epochs=5, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
        "    else:\n",
        "        history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "    history_dict[model_name] = history\n",
        "\n",
        "# 7. Evaluate models\n",
        "for model_name, model in models_dict.items():\n",
        "    print(f\"Evaluating {model_name} model...\")\n",
        "    if model_name in ['CNN', 'LSTM', 'Transformer']:\n",
        "        test_loss, test_acc = model.evaluate(X_test_reshaped, y_test)\n",
        "    else:\n",
        "        test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "    print(f\"{model_name} Test Accuracy: {test_acc}\")\n"
      ],
      "metadata": {
        "id": "gqxU57Tv-2_3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}